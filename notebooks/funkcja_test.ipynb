{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb62b06a",
   "metadata": {},
   "source": [
    "### Paste data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643765ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/interim/03_data_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4122f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a94e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training and test set\n",
    "df_train = df.drop([\"participant\", \"category\", \"set\"], axis=1)\n",
    "\n",
    "X = df_train.drop([\"label\"], axis=1)\n",
    "y = df_train[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c6f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train: {X_train.shape,y_train.shape} Test: {X_test.shape, y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1dce90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split feature subsets\n",
    "\n",
    "basic_features = [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]\n",
    "square_features = [\"acc_r\", \"gyr_r\"]\n",
    "pca_features = [\"pca_1\", \"pca_2\", \"pca_3\"]\n",
    "time_features = [f for f in df_train.columns if \"_temp_\" in f]\n",
    "freq_features = [f for f in df_train.columns if ((\"_freq\" in f) or (\"_pse\" in f))]\n",
    "cluster_features = [\"cluster\"]\n",
    "\n",
    "print(\"Basic Feature\", len(basic_features))\n",
    "print(\"Square Feature\", len(square_features))\n",
    "print(\"PCA Feature\", len(pca_features))\n",
    "print(\"Time Feature\", len(time_features))\n",
    "print(\"Frequency Feature\", len(freq_features))\n",
    "print(\"Cluster Feature\", len(cluster_features))\n",
    "\n",
    "feature_set_1 = list(set(basic_features))\n",
    "feature_set_2 = list(set(basic_features + square_features + pca_features))\n",
    "feature_set_3 = list(set(feature_set_2 + time_features))\n",
    "feature_set_4 = list(set(feature_set_3 + freq_features + cluster_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e924f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(\n",
    "        train_X,\n",
    "        train_y,\n",
    "        test_X,\n",
    "        min_samples_leaf=50,\n",
    "        criterion=\"gini\",\n",
    "        print_model_details=False,\n",
    "        export_tree_path=\"Example_graphs/Chapter7/\",\n",
    "        export_tree_name=\"tree.dot\",\n",
    "        gridsearch=True,\n",
    "    ):\n",
    "        # Create the model\n",
    "        if gridsearch:\n",
    "            tuned_parameters = [\n",
    "                {\n",
    "                    \"min_samples_leaf\": [2, 10, 50, 100, 200],\n",
    "                    \"criterion\": [\"gini\", \"entropy\"],\n",
    "                }\n",
    "            ]\n",
    "            dtree = GridSearchCV(\n",
    "                DecisionTreeClassifier(), tuned_parameters, cv=5, scoring=\"accuracy\"\n",
    "            )\n",
    "        else:\n",
    "            dtree = DecisionTreeClassifier(\n",
    "                min_samples_leaf=min_samples_leaf, criterion=criterion\n",
    "            )\n",
    "\n",
    "        # Fit the model\n",
    "\n",
    "        dtree.fit(train_X, train_y.values.ravel())\n",
    "\n",
    "        if gridsearch and print_model_details:\n",
    "            print(dtree.best_params_)\n",
    "\n",
    "        if gridsearch:\n",
    "            dtree = dtree.best_estimator_\n",
    "\n",
    "        # Apply the model\n",
    "        pred_prob_training_y = dtree.predict_proba(train_X)\n",
    "        pred_prob_test_y = dtree.predict_proba(test_X)\n",
    "        pred_training_y = dtree.predict(train_X)\n",
    "        pred_test_y = dtree.predict(test_X)\n",
    "        frame_prob_training_y = pd.DataFrame(\n",
    "            pred_prob_training_y, columns=dtree.classes_\n",
    "        )\n",
    "        frame_prob_test_y = pd.DataFrame(pred_prob_test_y, columns=dtree.classes_)\n",
    "\n",
    "        return pred_training_y, pred_test_y, frame_prob_training_y, frame_prob_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e8255a5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "117\n",
      "0.7114788004136504 acc_r_freq_2.5_Hz_ws_14\n",
      "0.7445708376421923 acc_r_pse\n",
      "0.755601516718373 acc_y_freq_0.357_Hz_ws_14\n",
      "0.7690451568424681 gyr_z_freq_1.786_Hz_ws_14\n",
      "0.8300586004825922 pca_2\n",
      "0.8579800068941744 acc_x\n",
      "0.8876249569114099 pca_1\n",
      "1\n",
      "['pca_1']\n",
      "116\n",
      "0.9283005860048259 acc_r_freq_2.5_Hz_ws_14\n",
      "0.9372630127542226 acc_y_pse\n",
      "0.9386418476387453 acc_y_freq_0.357_Hz_ws_14\n",
      "0.9617373319544984 pca_2\n",
      "0.9762150982419855 duration\n"
     ]
    }
   ],
   "source": [
    "#def forward_selection(max_features, X_train, y_train):\n",
    "        # Start with no features.\n",
    "max_features = 2\n",
    "ordered_features = []\n",
    "ordered_scores = []\n",
    "selected_features = []\n",
    "dtree = decision_tree\n",
    "prev_best_perf = 0\n",
    "\n",
    "# Select the appropriate number of features.\n",
    "for i in range(0, max_features):\n",
    "    print(i)\n",
    "    print(ordered_features)\n",
    "    # Determine the features left to select.\n",
    "    features_left = list(set(X_train.columns) - set(selected_features))\n",
    "    print(len(features_left))\n",
    "    best_perf = 0\n",
    "    best_attribute = \"\"\n",
    "\n",
    "    # For all features we can still select...\n",
    "    for f in features_left:\n",
    "        temp_selected_features = copy.deepcopy(selected_features)\n",
    "        temp_selected_features.append(f)\n",
    "\n",
    "        # Determine the accuracy of a decision tree learner if we were to add\n",
    "        # the feature.\n",
    "        (\n",
    "            pred_y_train,\n",
    "            pred_y_test,\n",
    "            prob_training_y,\n",
    "            prob_test_y,\n",
    "        ) = dtree(\n",
    "            X_train[temp_selected_features],\n",
    "            y_train,\n",
    "            X_train[temp_selected_features],\n",
    "        )\n",
    "        perf = accuracy_score(y_train, pred_y_train)\n",
    "        \n",
    "\n",
    "        # If the performance is better than what we have seen so far (we aim for high accuracy)\n",
    "        # we set the current feature to the best feature and the same for the best performance.\n",
    "        if perf > best_perf:\n",
    "            best_perf = perf\n",
    "            best_feature = f\n",
    "    # We select the feature with the best performance.\n",
    "    selected_features.append(best_feature)\n",
    "    prev_best_perf = best_perf\n",
    "    ordered_features.append(best_feature)\n",
    "    ordered_scores.append(best_perf)\n",
    "        #return selected_features, ordered_features, ordered_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dac87b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform forward feature selection using simple decision tree\n",
    "\n",
    "max_features = 10\n",
    "\n",
    "selected_features, ordered_features, ordered_scores = forward_selection(\n",
    "    max_features, X_train, y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b14e07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network,\n"
     ]
    }
   ],
   "source": [
    "print(\"Training neural network,\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fitness_tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e8530286831a628bb41aa380ed1d50ef3fed69013ba6cacf0739f86cf1c4b4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
